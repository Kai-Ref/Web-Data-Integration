{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code combines all of the three gold standards into one big file\n",
    "\n",
    "# EA and TM Dataset\n",
    "perfect_matches_ea_tm = pd.read_csv(\"ea_tm/perfect_matches_ea_tm.csv\")\n",
    "corner_cases_ea_tm = pd.read_csv(\"ea_tm/corner_cases_ea_tm.csv\")\n",
    "non_matches_ea_tm = pd.read_csv(\"ea_tm/non_matches_ea_tm.csv\")\n",
    "\n",
    "# FM and EA Dataset\n",
    "perfect_matches_fm_ea = pd.read_csv(\"fm_ea/perfect_matches_fm_ea_v2.csv\")\n",
    "corner_cases_fm_ea = pd.read_csv(\"fm_ea/corner_cases_fm_ea_v2.csv\")\n",
    "non_matches_fm_ea = pd.read_csv(\"fm_ea/non_matches_fm_ea_v2.csv\")\n",
    "\n",
    "# FM and TM Dataset\n",
    "perfect_matches_fm_tm = pd.read_csv(\"fm_tm/perfect_matches_fm_tm_v3.csv\")\n",
    "corner_cases_fm_tm = pd.read_csv(\"fm_tm/corner_cases_fm_tm_v3.csv\")\n",
    "non_matches_fm_tm = pd.read_csv(\"fm_tm/non_matches_fm_tm_v3.csv\")\n",
    "\n",
    "# perfect_matches\n",
    "perfect_matches = pd.concat([\n",
    "    perfect_matches_ea_tm,\n",
    "    perfect_matches_fm_ea,\n",
    "    perfect_matches_fm_tm\n",
    "])\n",
    "\n",
    "# corner_cases\n",
    "corner_cases = pd.concat([\n",
    "    corner_cases_ea_tm,\n",
    "    corner_cases_fm_ea,\n",
    "    corner_cases_fm_tm\n",
    "])\n",
    "\n",
    "# non_matches\n",
    "non_matches = pd.concat([\n",
    "    non_matches_ea_tm,\n",
    "    non_matches_fm_ea,\n",
    "    non_matches_fm_tm\n",
    "])\n",
    "\n",
    "\n",
    "# Concat all of the datasets\n",
    "gold_standard = pd.concat([perfect_matches, corner_cases, non_matches])\n",
    "\n",
    "number_extract_perfect_matches = 100\n",
    "number_extract_corner_cases = 200\n",
    "number_extract_non_matches = 200\n",
    "\n",
    "# Gold Standard ea_tm\n",
    "gold_standard_ea_tm = pd.concat([\n",
    "    perfect_matches_ea_tm.sample(n=number_extract_perfect_matches, random_state=42), \n",
    "    corner_cases_ea_tm.sample(n=number_extract_corner_cases, random_state=42), \n",
    "    non_matches_ea_tm.sample(n=number_extract_non_matches, random_state=42)\n",
    "    ])\n",
    "\n",
    "# Gold Standard fm_ea\n",
    "gold_standard_fm_ea = pd.concat([\n",
    "    perfect_matches_fm_ea.sample(n=number_extract_perfect_matches, random_state=42), \n",
    "    corner_cases_fm_ea.sample(n=number_extract_corner_cases, random_state=42), \n",
    "    non_matches_fm_ea.sample(n=number_extract_non_matches, random_state=42)\n",
    "    ])\n",
    "\n",
    "# Gold Standard fm_tm\n",
    "gold_standard_fm_tm = pd.concat([\n",
    "    perfect_matches_fm_tm.sample(n=number_extract_perfect_matches, random_state=42), \n",
    "    corner_cases_fm_tm.sample(n=number_extract_corner_cases, random_state=42), \n",
    "    non_matches_fm_tm.sample(n=number_extract_non_matches, random_state=42)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_standard_fm_tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard_ea_tm.iloc[:, [0, 1, -1]].to_csv(\"gold_standard_ea_tm.csv\", index=False)\n",
    "gold_standard_fm_ea.iloc[:, [0, 1, -1]].to_csv(\"gold_standard_fm_ea.csv\", index=False)\n",
    "# gold_standard_fm_tm.iloc[:, [0, 1, -1]].to_csv(\"gold_standard_fm_tm_v3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following code added by Jan\n",
    "to produce gold standard training sets to the 500 entity test sets to ensure all models (ML and linear) are tested on same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.0 300 300\n"
     ]
    }
   ],
   "source": [
    "# fm_tm\n",
    "# Get the indices of the sampled rows\n",
    "sampled_indices_pm = perfect_matches_fm_tm.sample(n=number_extract_perfect_matches, random_state=42).index\n",
    "sampled_indices_cc = corner_cases_fm_tm.sample(n=number_extract_corner_cases, random_state=42).index\n",
    "sampled_indices_nm = non_matches_fm_tm.sample(n=number_extract_non_matches, random_state=42).index\n",
    "\n",
    "# Get the rows that were not sampled\n",
    "remaining_pm = perfect_matches_fm_tm.drop(sampled_indices_pm)\n",
    "remaining_cc = corner_cases_fm_tm.drop(sampled_indices_cc)\n",
    "remaining_nm = non_matches_fm_tm.drop(sampled_indices_nm)\n",
    "\n",
    "# Concatenate the remaining rows in ratio of 1:2:2 (DEFINE FUNCTIONS IN CODE BELOW FIRST!)\n",
    "gold_standard_fm_tm_train_NEW = create_goldstandard_balance_1_2_2(remaining_pm, remaining_cc, remaining_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 56 56\n"
     ]
    }
   ],
   "source": [
    "# fm_ea\n",
    "# Get the indices of the sampled rows\n",
    "sampled_indices_pm = perfect_matches_fm_ea.sample(n=number_extract_perfect_matches, random_state=42).index\n",
    "sampled_indices_cc = corner_cases_fm_ea.sample(n=number_extract_corner_cases, random_state=42).index\n",
    "sampled_indices_nm = non_matches_fm_ea.sample(n=number_extract_non_matches, random_state=42).index\n",
    "\n",
    "# Get the rows that were not sampled\n",
    "remaining_pm = perfect_matches_fm_ea.drop(sampled_indices_pm)\n",
    "remaining_cc = corner_cases_fm_ea.drop(sampled_indices_cc)\n",
    "remaining_nm = non_matches_fm_ea.drop(sampled_indices_nm)\n",
    "\n",
    "# Concatenate the remaining rows in ratio of 1:2:2 (DEFINE FUNCTIONS IN CODE BELOW FIRST!)\n",
    "gold_standard_fm_ea_train_NEW = create_goldstandard_balance_1_2_2(remaining_pm, remaining_cc, remaining_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 216 16\n"
     ]
    }
   ],
   "source": [
    "# ea_tm\n",
    "# Get the indices of the sampled rows\n",
    "sampled_indices_pm = perfect_matches_ea_tm.sample(n=number_extract_perfect_matches, random_state=42).index\n",
    "sampled_indices_cc = corner_cases_ea_tm.sample(n=number_extract_corner_cases, random_state=42).index\n",
    "sampled_indices_nm = non_matches_ea_tm.sample(n=number_extract_non_matches, random_state=42).index\n",
    "\n",
    "# Get the rows that were not sampled\n",
    "remaining_pm = perfect_matches_ea_tm.drop(sampled_indices_pm)\n",
    "remaining_cc = corner_cases_ea_tm.drop(sampled_indices_cc)\n",
    "remaining_nm = non_matches_ea_tm.drop(sampled_indices_nm)\n",
    "\n",
    "# Concatenate the remaining rows in ratio of 1:2:2 (DEFINE FUNCTIONS IN CODE BELOW FIRST!)\n",
    "remaining_cc_sampled = remaining_cc.sample(n=216, random_state=42)\n",
    "gold_standard_ea_tm_train_NEW = pd.concat([remaining_pm, remaining_cc_sampled, remaining_nm])\n",
    "print(len(remaining_pm), len(remaining_cc_sampled), len(remaining_nm))\n",
    "# # of non-matches is too small (16) \n",
    "# compensate by adding 100 from corner cases\n",
    "# since perfect matches are 58 (58*2 = 116 and there is already 16 non-matches) so its balanced again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n",
      "140\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "print(len(gold_standard_fm_tm_train_NEW))\n",
    "print(len(gold_standard_fm_ea_train_NEW))\n",
    "print(len(gold_standard_ea_tm_train_NEW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard_fm_tm_train_NEW.iloc[:, [0, 1, -1]].to_csv(\"gold_standard_fm_tm_train_NEW.csv\", index=False)\n",
    "gold_standard_fm_ea_train_NEW.iloc[:, [0, 1, -1]].to_csv(\"gold_standard_ea_fm_train_NEW.csv\", index=False)\n",
    "gold_standard_ea_tm_train_NEW.iloc[:, [0, 1, -1]].to_csv(\"gold_standard_ea_tm_train_NEW.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_information(df, name):\n",
    "    overall_number_matches = sum(df['match'] == True)\n",
    "    overall_number_nonmatches = len(df) - overall_number_matches\n",
    "\n",
    "    print(\"-\"*5, name, \"-\"*5)\n",
    "    print(f\"Number of rows: {len(df)}\")\n",
    "    print(f\"Number of matches: {overall_number_matches}, {round(overall_number_matches/len(df)*100, 2)}%\")\n",
    "    print(f\"Number of non-matches: {overall_number_nonmatches}, {round(overall_number_nonmatches/len(df)*100, 2)}%\")\n",
    "    print()\n",
    "\n",
    "    # df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save gold standard to disk, only the keys and the match column\n",
    "gold_standard.iloc[:, [0, 1, -1]].to_csv(\"gold_standard.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gold Standard -----\n",
      "Number of rows: 4968\n",
      "Number of matches: 3357, 67.57%\n",
      "Number of non-matches: 1611, 32.43%\n",
      "\n",
      "----- Perfect Matches EA and TM -----\n",
      "Number of rows: 158\n",
      "Number of matches: 158, 100.0%\n",
      "Number of non-matches: 0, 0.0%\n",
      "\n",
      "----- Corner Cases EA and TM -----\n",
      "Number of rows: 666\n",
      "Number of matches: 527, 79.13%\n",
      "Number of non-matches: 139, 20.87%\n",
      "\n",
      "----- Non Matches EA and TM -----\n",
      "Number of rows: 216\n",
      "Number of matches: 0, 0.0%\n",
      "Number of non-matches: 216, 100.0%\n",
      "\n",
      "----- Perfect Matches FM and EA -----\n",
      "Number of rows: 128\n",
      "Number of matches: 128, 100.0%\n",
      "Number of non-matches: 0, 0.0%\n",
      "\n",
      "----- Corner Cases FM and EA -----\n",
      "Number of rows: 356\n",
      "Number of matches: 264, 74.16%\n",
      "Number of non-matches: 92, 25.84%\n",
      "\n",
      "----- Non Matches FM and EA -----\n",
      "Number of rows: 396\n",
      "Number of matches: 0, 0.0%\n",
      "Number of non-matches: 396, 100.0%\n",
      "\n",
      "----- Perfect Matches FM and TM -----\n",
      "Number of rows: 2048\n",
      "Number of matches: 2048, 100.0%\n",
      "Number of non-matches: 0, 0.0%\n",
      "\n",
      "----- Corner Cases FM and TM -----\n",
      "Number of rows: 500\n",
      "Number of matches: 232, 46.4%\n",
      "Number of non-matches: 268, 53.6%\n",
      "\n",
      "----- Non Matches FM and TM -----\n",
      "Number of rows: 500\n",
      "Number of matches: 0, 0.0%\n",
      "Number of non-matches: 500, 100.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_information(gold_standard, \"Gold Standard\")\n",
    "\n",
    "print_information(perfect_matches_ea_tm, \"Perfect Matches EA and TM\")\n",
    "print_information(corner_cases_ea_tm, \"Corner Cases EA and TM\")\n",
    "print_information(non_matches_ea_tm, \"Non Matches EA and TM\")\n",
    "\n",
    "print_information(perfect_matches_fm_ea, \"Perfect Matches FM and EA\")\n",
    "print_information(corner_cases_fm_ea, \"Corner Cases FM and EA\")\n",
    "print_information(non_matches_fm_ea, \"Non Matches FM and EA\")\n",
    "\n",
    "print_information(perfect_matches_fm_tm, \"Perfect Matches FM and TM\")\n",
    "print_information(corner_cases_fm_tm, \"Corner Cases FM and TM\")\n",
    "print_information(non_matches_fm_tm, \"Non Matches FM and TM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train-Test-Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_goldstandard_train_test_split(df, test_size=0.2, min_train_rows=500):\n",
    "    \"\"\"Create a train-test split of the goldstandard data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The goldstandard data.\n",
    "        test_size (float): The proportion of the data to be used for testing.\n",
    "        min_train_rows (int): The minimum number of rows in the training dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The training data.\n",
    "        pd.DataFrame: The testing data.\n",
    "    \"\"\"\n",
    "    # Check if the minimum number of rows in the training dataset is less than the total number of rows\n",
    "    if min_train_rows >= len(df):\n",
    "        print(f\"The minimum number of rows in the training dataset should be less than the total number of rows. Dataset has {len(df)} rows. Minimum number of rows in the training dataset is {min_train_rows}.\")\n",
    "\n",
    "    # Perform the train-test split\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=42)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def create_goldstandard_balance_1_2_2(perfect_matches:pd.DataFrame, corner_cases:pd.DataFrame, non_matches:pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    num_perfect_matches = len(perfect_matches)\n",
    "    num_corner_cases    = len(corner_cases)\n",
    "    num_non_matches     = len(non_matches)\n",
    "\n",
    "    num_corner_cases = min(num_corner_cases, num_non_matches)\n",
    "    num_non_matches  = min(num_corner_cases, num_non_matches)\n",
    "\n",
    "    if num_corner_cases < (2 * num_perfect_matches):\n",
    "        num_perfect_matches = num_corner_cases / 2\n",
    "    else:\n",
    "        num_corner_cases = 2 * num_perfect_matches\n",
    "        num_non_matches  = 2 * num_perfect_matches\n",
    "    print(num_perfect_matches, num_corner_cases, num_non_matches)\n",
    "\n",
    "    # Gold Standard\n",
    "    gold_standard = pd.concat([\n",
    "        perfect_matches.sample(n=int(num_perfect_matches), random_state=42), \n",
    "        corner_cases.sample(n=int(num_corner_cases), random_state=42), \n",
    "        non_matches.sample(n=int(num_non_matches), random_state=42)\n",
    "        ])\n",
    "    \n",
    "    return gold_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standards = [\n",
    "    # 'ea_tm',\n",
    "    # 'fm_ea',\n",
    "    'fm_tm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- df_perfect_matches -----\n",
      "Number of rows: 2048\n",
      "Number of matches: 2048, 100.0%\n",
      "Number of non-matches: 0, 0.0%\n",
      "\n",
      "----- df_corner_cases -----\n",
      "Number of rows: 500\n",
      "Number of matches: 232, 46.4%\n",
      "Number of non-matches: 268, 53.6%\n",
      "\n",
      "----- df_non_matches -----\n",
      "Number of rows: 500\n",
      "Number of matches: 0, 0.0%\n",
      "Number of non-matches: 500, 100.0%\n",
      "\n",
      "250.0 500 500\n",
      "----- Training -----\n",
      "Number of rows: 1000\n",
      "Number of matches: 380, 38.0%\n",
      "Number of non-matches: 620, 62.0%\n",
      "\n",
      "----- Test -----\n",
      "Number of rows: 250\n",
      "Number of matches: 102, 40.8%\n",
      "Number of non-matches: 148, 59.2%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "version = \"_v3\"\n",
    "for gold_standard in gold_standards:\n",
    "    df_perfect_matches = pd.read_csv(f\"{gold_standard}/perfect_matches_{gold_standard}{version}.csv\")\n",
    "    df_corner_cases = pd.read_csv(f\"{gold_standard}/corner_cases_{gold_standard}{version}.csv\")\n",
    "    df_non_matches = pd.read_csv(f\"{gold_standard}/non_matches_{gold_standard}{version}.csv\")\n",
    "\n",
    "    print_information(df_perfect_matches, \"df_perfect_matches\")\n",
    "    print_information(df_corner_cases,  \"df_corner_cases\")\n",
    "    print_information(df_non_matches, \"df_non_matches\")\n",
    "\n",
    "    df_balanced = create_goldstandard_balance_1_2_2(df_perfect_matches, df_corner_cases, df_non_matches)\n",
    "    train, test = create_goldstandard_train_test_split(df_balanced)\n",
    "\n",
    "    print_information(train, \"Training\")\n",
    "    print_information(test, \"Test\")\n",
    "\n",
    "    train.to_csv(f\"gold_standard_{gold_standard}_train{version}.csv\", index=False)\n",
    "    test.to_csv(f\"gold_standard_{gold_standard}_test{version}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- fm_tm -----\n"
     ]
    }
   ],
   "source": [
    "for gold_standard in gold_standards:\n",
    "    print(\"-\"*5, gold_standard, \"-\"*5)\n",
    "    try:\n",
    "        pd.read_csv(f\"gold_standard_{gold_standard}_train{version}.csv\")[[\"df1\", \"df2\", \"match\"]].to_csv(f\"gold_standard_{gold_standard}_train{version}.csv\", index=False)\n",
    "        pd.read_csv(f\"gold_standard_{gold_standard}_test{version}.csv\")[[\"df1\", \"df2\", \"match\"]].to_csv(f\"gold_standard_{gold_standard}_test{version}.csv\", index=False)\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
