{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code combines all of the three gold standards into one big file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# EA and TM Dataset\n",
    "perfect_matches_ea_tm = pd.read_csv(\"ea_tm/perfect_matches_ea_tm.csv\")\n",
    "corner_cases_ea_tm = pd.read_csv(\"ea_tm/corner_cases_ea_tm.csv\")\n",
    "non_matches_ea_tm = pd.read_csv(\"ea_tm/non_matches_ea_tm.csv\")\n",
    "\n",
    "# FM and EA Dataset\n",
    "perfect_matches_fm_ea = pd.read_csv(\"fm_ea/perfect_matches_fm_ea_v2.csv\")\n",
    "corner_cases_fm_ea = pd.read_csv(\"fm_ea/corner_cases_fm_ea_v2.csv\")\n",
    "non_matches_fm_ea = pd.read_csv(\"fm_ea/non_matches_fm_ea_v2.csv\")\n",
    "\n",
    "# FM and TM Dataset\n",
    "perfect_matches_fm_tm = pd.read_csv(\"fm_tm/perfect_matches_tm_fm_v2.csv\")\n",
    "corner_cases_fm_tm = pd.read_csv(\"fm_tm/corner_cases_tm_fm_v2.csv\")\n",
    "non_matches_fm_tm = pd.read_csv(\"fm_tm/non_matches_tm_fm_v2.csv\")\n",
    "\n",
    "# perfect_matches\n",
    "perfect_matches = pd.concat([\n",
    "    perfect_matches_ea_tm,\n",
    "    perfect_matches_fm_ea,\n",
    "    perfect_matches_fm_tm\n",
    "])\n",
    "\n",
    "# corner_cases\n",
    "corner_cases = pd.concat([\n",
    "    corner_cases_ea_tm,\n",
    "    corner_cases_fm_ea,\n",
    "    corner_cases_fm_tm\n",
    "])\n",
    "\n",
    "# non_matches\n",
    "non_matches = pd.concat([\n",
    "    non_matches_ea_tm,\n",
    "    non_matches_fm_ea,\n",
    "    non_matches_fm_tm\n",
    "])\n",
    "\n",
    "\n",
    "# Concat all of the datasets\n",
    "gold_standard = pd.concat([perfect_matches, corner_cases, non_matches])\n",
    "\n",
    "number_extract_perfect_matches = 100\n",
    "number_extract_corner_cases = 200\n",
    "number_extract_non_matches = 200\n",
    "\n",
    "# Gold Standard ea_tm\n",
    "gold_standard_ea_tm = pd.concat([\n",
    "    perfect_matches_ea_tm.sample(n=number_extract_perfect_matches, random_state=42), \n",
    "    corner_cases_ea_tm.sample(n=number_extract_corner_cases, random_state=42), \n",
    "    non_matches_ea_tm.sample(n=number_extract_non_matches, random_state=42)\n",
    "    ])\n",
    "\n",
    "# Gold Standard fm_ea\n",
    "gold_standard_fm_ea = pd.concat([\n",
    "    perfect_matches_fm_ea.sample(n=number_extract_perfect_matches, random_state=42), \n",
    "    corner_cases_fm_ea.sample(n=number_extract_corner_cases, random_state=42), \n",
    "    non_matches_fm_ea.sample(n=number_extract_non_matches, random_state=42)\n",
    "    ])\n",
    "\n",
    "# Gold Standard fm_tm\n",
    "gold_standard_fm_tm = pd.concat([\n",
    "    perfect_matches_fm_tm.sample(n=number_extract_perfect_matches, random_state=42), \n",
    "    corner_cases_fm_tm, \n",
    "    non_matches_fm_tm.sample(n=number_extract_non_matches, random_state=42)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_matches_fm_tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_standard_ea_tm.iloc[:, [0, 1, -1]].to_csv(\"gold_standard_ea_tm.csv\", index=False)\n",
    "gold_standard_fm_ea.iloc[:, [0, 1, -1]].to_csv(\"gold_standard_fm_ea.csv\", index=False)\n",
    "gold_standard_fm_tm.iloc[:, [0, 1, -1]].to_csv(\"gold_standard_fm_tm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_information(df, name):\n",
    "    overall_number_matches = sum(df['match'] == True)\n",
    "    overall_number_nonmatches = len(df) - overall_number_matches\n",
    "\n",
    "    print(\"-\"*5, name, \"-\"*5)\n",
    "    print(f\"Number of rows: {len(df)}\")\n",
    "    print(f\"Number of matches: {overall_number_matches}, {round(overall_number_matches/len(df)*100, 2)}%\")\n",
    "    print(f\"Number of non-matches: {overall_number_nonmatches}, {round(overall_number_nonmatches/len(df)*100, 2)}%\")\n",
    "    print()\n",
    "\n",
    "    # df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save gold standard to disk, only the keys and the match column\n",
    "gold_standard.iloc[:, [0, 1, -1]].to_csv(\"gold_standard.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gold Standard -----\n",
      "Number of rows: 2820\n",
      "Number of matches: 1703, 60.39%\n",
      "Number of non-matches: 1117, 39.61%\n",
      "\n",
      "----- Perfect Matches EA and TM -----\n",
      "Number of rows: 158\n",
      "Number of matches: 158, 100.0%\n",
      "Number of non-matches: 0, 0.0%\n",
      "\n",
      "----- Corner Cases EA and TM -----\n",
      "Number of rows: 666\n",
      "Number of matches: 527, 79.13%\n",
      "Number of non-matches: 139, 20.87%\n",
      "\n",
      "----- Non Matches EA and TM -----\n",
      "Number of rows: 216\n",
      "Number of matches: 0, 0.0%\n",
      "Number of non-matches: 216, 100.0%\n",
      "\n",
      "----- Perfect Matches FM and EA -----\n",
      "Number of rows: 128\n",
      "Number of matches: 128, 100.0%\n",
      "Number of non-matches: 0, 0.0%\n",
      "\n",
      "----- Corner Cases FM and EA -----\n",
      "Number of rows: 356\n",
      "Number of matches: 264, 74.16%\n",
      "Number of non-matches: 92, 25.84%\n",
      "\n",
      "----- Non Matches FM and EA -----\n",
      "Number of rows: 396\n",
      "Number of matches: 0, 0.0%\n",
      "Number of non-matches: 396, 100.0%\n",
      "\n",
      "----- Perfect Matches FM and TM -----\n",
      "Number of rows: 544\n",
      "Number of matches: 544, 100.0%\n",
      "Number of non-matches: 0, 0.0%\n",
      "\n",
      "----- Corner Cases FM and TM -----\n",
      "Number of rows: 156\n",
      "Number of matches: 82, 52.56%\n",
      "Number of non-matches: 74, 47.44%\n",
      "\n",
      "----- Non Matches FM and TM -----\n",
      "Number of rows: 200\n",
      "Number of matches: 0, 0.0%\n",
      "Number of non-matches: 200, 100.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_information(gold_standard, \"Gold Standard\")\n",
    "\n",
    "print_information(perfect_matches_ea_tm, \"Perfect Matches EA and TM\")\n",
    "print_information(corner_cases_ea_tm, \"Corner Cases EA and TM\")\n",
    "print_information(non_matches_ea_tm, \"Non Matches EA and TM\")\n",
    "\n",
    "print_information(perfect_matches_fm_ea, \"Perfect Matches FM and EA\")\n",
    "print_information(corner_cases_fm_ea, \"Corner Cases FM and EA\")\n",
    "print_information(non_matches_fm_ea, \"Non Matches FM and EA\")\n",
    "\n",
    "print_information(perfect_matches_fm_tm, \"Perfect Matches FM and TM\")\n",
    "print_information(corner_cases_fm_tm, \"Corner Cases FM and TM\")\n",
    "print_information(non_matches_fm_tm, \"Non Matches FM and TM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train-Test-Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_goldstandard_train_test_split(df, test_size=0.2, min_train_rows=500):\n",
    "    \"\"\"Create a train-test split of the goldstandard data.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The goldstandard data.\n",
    "        test_size (float): The proportion of the data to be used for testing.\n",
    "        min_train_rows (int): The minimum number of rows in the training dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The training data.\n",
    "        pd.DataFrame: The testing data.\n",
    "    \"\"\"\n",
    "    # Check if the minimum number of rows in the training dataset is less than the total number of rows\n",
    "    if min_train_rows >= len(df):\n",
    "        print(f\"The minimum number of rows in the training dataset should be less than the total number of rows. Dataset has {len(df)} rows. Minimum number of rows in the training dataset is {min_train_rows}.\")\n",
    "\n",
    "    # Perform the train-test split\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=42)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def create_goldstandard_balance_1_2_2(perfect_matches:pd.DataFrame, corner_cases:pd.DataFrame, non_matches:pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    num_perfect_matches = len(perfect_matches)\n",
    "    num_corner_cases    = len(corner_cases)\n",
    "    num_non_matches     = len(non_matches)\n",
    "\n",
    "    num_corner_cases = min(num_corner_cases, num_non_matches)\n",
    "    num_non_matches  = min(num_corner_cases, num_non_matches)\n",
    "\n",
    "    if num_corner_cases < (2 * num_perfect_matches):\n",
    "        num_perfect_matches = num_corner_cases / 2\n",
    "    else:\n",
    "        num_corner_cases = 2 * num_perfect_matches\n",
    "        num_non_matches  = 2 * num_perfect_matches\n",
    "    print(num_perfect_matches, num_corner_cases, num_non_matches)\n",
    "\n",
    "    # Gold Standard\n",
    "    gold_standard = pd.concat([\n",
    "        perfect_matches.sample(n=int(num_perfect_matches), random_state=42), \n",
    "        corner_cases.sample(n=int(num_corner_cases), random_state=42), \n",
    "        non_matches.sample(n=int(num_non_matches), random_state=42)\n",
    "        ])\n",
    "    \n",
    "    return gold_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.0 216 216\n",
      "128 256 256\n",
      "92.0 184 184\n",
      "The minimum number of rows in the training dataset should be less than the total number of rows. Dataset has 460 rows. Minimum number of rows in the training dataset is 500.\n"
     ]
    }
   ],
   "source": [
    "gold_standards = [\n",
    "    'ea_tm',\n",
    "    'fm_ea',\n",
    "    'fm_tm'\n",
    "]\n",
    "\n",
    "\n",
    "for gold_standard in gold_standards:\n",
    "    try:\n",
    "        df_perfect_matches = pd.read_csv(f\"{gold_standard}/perfect_matches_{gold_standard}_v2.csv\")\n",
    "    except:\n",
    "        df_perfect_matches = pd.read_csv(f\"{gold_standard}/perfect_matches_{gold_standard}.csv\")\n",
    "\n",
    "    try:\n",
    "        df_corner_cases = pd.read_csv(f\"{gold_standard}/corner_cases_{gold_standard}_v2.csv\")\n",
    "    except:\n",
    "        df_corner_cases = pd.read_csv(f\"{gold_standard}/corner_cases_{gold_standard}.csv\")\n",
    "\n",
    "    try:\n",
    "        df_non_matches = pd.read_csv(f\"{gold_standard}/non_matches_{gold_standard}_v2.csv\")\n",
    "    except:\n",
    "        df_non_matches = pd.read_csv(f\"{gold_standard}/non_matches_{gold_standard}.csv\")\n",
    "\n",
    "    df_balanced = create_goldstandard_balance_1_2_2(df_perfect_matches, df_corner_cases, df_non_matches)\n",
    "    train, test = create_goldstandard_train_test_split(df_balanced)\n",
    "    train.to_csv(f\"gold_standard_{gold_standard}_train.csv\", index=False)\n",
    "    test.to_csv(f\"gold_standard_{gold_standard}_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
